{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import unicode_literals\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "from model_davenet import load_DAVEnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력과 출력의 차원수가 동일하다\n",
    "class Context_Gating(nn.Module):\n",
    "    def __init__(self, dimension):\n",
    "        super(Context_Gating, self).__init__()\n",
    "        self.fc = nn.Linear(dimension, dimension)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.fc(x)          \n",
    "        x = th.cat((x, x1), 1)   # 차원 = 2 * dimension\n",
    "        return F.glu(x, 1)       # 차원 = dimension , glu가 반만 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력차원을 출력차원으로 맞춰주고 context_gating을 통과시켜준다\n",
    "class Gated_Embedding_Unit(nn.Module):\n",
    "    def __init__(self, input_dimension, output_dimension):\n",
    "        super(Gated_Embedding_Unit, self).__init__()\n",
    "        self.fc = nn.Linear(input_dimension, output_dimension)  # 차원 맞추기\n",
    "        self.cg = Context_Gating(output_dimension)              # Context Gating \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)         \n",
    "        x = self.cg(x)         \n",
    "        return x               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차원수도 조절해주고 max pooling도 적용해준다. ex. (300,20) -> (1024)\n",
    "class Sentence_Maxpool(nn.Module):\n",
    "    def __init__(self, word_dimension, output_dim):\n",
    "        super(Sentence_Maxpool, self).__init__()\n",
    "        self.fc = nn.Linear(word_dimension, output_dim) #차원 맞추기\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = F.relu(x)\n",
    "        return th.max(x, dim=1)[0]  # max pooling으로 (1024,20) -> (1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이때 input_dimension은 embed_dim/2로 들어가야해!\n",
    "class Fused_Gated_Unit(nn.Module):\n",
    "    def __init__(self, input_dimension, output_dimension):\n",
    "        super(Fused_Gated_Unit, self).__init__()\n",
    "        self.fc_audio = nn.Linear(input_dimension, output_dimension)\n",
    "        self.fc_text = nn.Linear(input_dimension, output_dimension)\n",
    "        self.cg = Context_Gating(output_dimension)\n",
    "\n",
    "    def forward(self, audio, text):\n",
    "        audio = self.fc_audio(audio)\n",
    "        text = self.fc_text(text)\n",
    "        x = audio + text\n",
    "        x = self.cg(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            embd_dim=1024,\n",
    "            video_dim=2048,\n",
    "            we_dim=300\n",
    "    ):\n",
    "        super(Net, self).__init__()\n",
    "        self.DAVEnet = load_DAVEnet()\n",
    "\n",
    "        # 각각의 차원: 원하는 차원 / 2\n",
    "        self.GU_audio = Gated_Embedding_Unit(1024, embd_dim // 2)\n",
    "        self.GU_video = Gated_Embedding_Unit(video_dim, embd_dim // 2)\n",
    "        self.text_pooling_caption = Sentence_Maxpool(we_dim, embd_dim // 2)\n",
    "\n",
    "        # correlation반영\n",
    "        self.GU_fuse= Fused_Gated_Unit(embd_dim // 2, embd_dim)\n",
    "\n",
    "    def forward(self, video, audio_input, nframes, text=None):\n",
    "        video = self.GU_video(video)\n",
    "        audio = self.DAVEnet(audio_input)\n",
    "        text = self.text_pooling_caption(text)\n",
    "        if not self.training: # controlled by net.train() / net.eval() (use for downstream tasks) \n",
    "            pooling_ratio = round(audio_input.size(-1) / audio.size(-1))    # 입력 오디오 길이와 오디오 임베딩 길이 계산\n",
    "            nframes.div_(pooling_ratio)                                     # 오디오 프레임 수를 풀링 비율로 나눈다.\n",
    "            audioPoolfunc = th.nn.AdaptiveAvgPool2d((1, 1))                 # 입력 길이 맞추기\n",
    "            audio_outputs = audio.unsqueeze(2)                              # 풀링을 위해 차원 추가\n",
    "            pooled_audio_outputs_list = []\n",
    "            for idx in range(audio.shape[0]):\n",
    "                nF = max(1, nframes[idx])\n",
    "                pooled_audio_outputs_list.append(audioPoolfunc(audio_outputs[idx][:, :, 0:nF]).unsqueeze(0))\n",
    "            audio = th.cat(pooled_audio_outputs_list).squeeze(3).squeeze(2)\n",
    "        else:\n",
    "            audio = audio.mean(dim=2) # this averages features from 0 padding too\n",
    "       \n",
    "        audio_text = self.GU_fuse(audio, text)\n",
    "        audio_video = self.GU_fuse(audio, video)\n",
    "        text_video = self.GU_fuse(text, video)\n",
    "        #return audio_text, video -> 기존에는 반환값 2개\n",
    "        return audio_text, audio_video, text_video"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
