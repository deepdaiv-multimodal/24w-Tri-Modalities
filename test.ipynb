{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\heeryung\\anaconda3\\envs\\jiwon2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from dataset.msrvtt_dataloader import MSRVTT_DataLoader\n",
    "from model.fusion_model import EverythingAtOnceModel\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(\n",
    "    we_path='./data/GoogleNews-vectors-negative300.bin',\n",
    "    data_path='C:/Users/heeryung/code/24w_deep_daiv/msrvtt_category_test.pkl',\n",
    "    checkpoint_path='C:/Users/heeryung/code/24w_deep_daiv/ckpt/trial5_classifier/epoch200.pth',\n",
    "    token_projection='projection_net',\n",
    "    use_softmax=False,\n",
    "    use_cls_token=False,\n",
    "    num_classes=20,\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(args.checkpoint_path)\n",
    "\n",
    "we = None \n",
    "we = KeyedVectors.load_word2vec_format(args.we_path, binary=True)\n",
    "\n",
    "dataset = MSRVTT_DataLoader(data_path=args.data_path, we=we)\n",
    "data_loader = DataLoader(dataset, batch_size=args.batch_size)\n",
    "\n",
    "net = EverythingAtOnceModel(args).cuda()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr =0.001)\n",
    "\n",
    "net.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "net.eval()\n",
    "\n",
    "def get_soft_voting(va, at, tv):\n",
    "    # Soft voting by averaging the probabilities\n",
    "    soft_vote = (va + at + tv) / 3\n",
    "    _, soft_vote_preds = torch.max(soft_vote, 1)\n",
    "    return soft_vote_preds\n",
    "\n",
    "def get_hard_voting(va_preds, at_preds, tv_preds):\n",
    "    # Hard voting by selecting the most frequent prediction\n",
    "    combined_preds = torch.stack((va_preds, at_preds, tv_preds), dim=1)\n",
    "    hard_vote, _ = torch.mode(combined_preds, dim=1)\n",
    "    return hard_vote\n",
    "\n",
    "def get_predictions(va, at, tv):\n",
    "    _, va_preds = torch.max(va, 1)\n",
    "    _, at_preds = torch.max(at, 1)\n",
    "    _, tv_preds = torch.max(tv, 1)\n",
    "    return va_preds, at_preds, tv_preds\n",
    "\n",
    "def calculate_accuracy(predictions, labels):\n",
    "    correct = (predictions == labels).sum().item()\n",
    "    total = labels.size(0)\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "total_samples = 0\n",
    "total_accuracy = 0\n",
    "total_video_correct = 0\n",
    "total_audio_correct = 0\n",
    "total_text_correct = 0\n",
    "total_hard_vote_correct = 0\n",
    "total_soft_vote_correct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0') / tensor([10,  3, 13,  7,  9,  6,  0,  2,  1,  2,  9, 13, 12,  9,  2,  3],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323],\n",
      "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
      "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
      "          0.2847, -0.4040, -0.0351, -1.1323]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0') / tensor([13,  7,  9,  4,  0,  7,  4,  3,  5,  0,  6,  9, 16, 18, 18,  7],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, text\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m], text\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     12\u001b[0m pred \u001b[38;5;241m=\u001b[39m net(video, audio, nframes, text, category) \u001b[38;5;66;03m# [batch_size, 20]\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m pred_category \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(pred, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# [batch_size,]\u001b[39;00m\n\u001b[0;32m     15\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean((pred_category \u001b[38;5;241m==\u001b[39m category)\u001b[38;5;241m.\u001b[39mfloat()) \u001b[38;5;66;03m# [batch_size,]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\heeryung\\anaconda3\\envs\\jiwon2\\lib\\site-packages\\torch\\_tensor.py:427\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    424\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[0;32m    425\u001b[0m     )\n\u001b[0;32m    426\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[1;32m--> 427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\heeryung\\anaconda3\\envs\\jiwon2\\lib\\site-packages\\torch\\_tensor_str.py:637\u001b[0m, in \u001b[0;36m_str\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    636\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[1;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\heeryung\\anaconda3\\envs\\jiwon2\\lib\\site-packages\\torch\\_tensor_str.py:568\u001b[0m, in \u001b[0;36m_str_intern\u001b[1;34m(inp, tensor_contents)\u001b[0m\n\u001b[0;32m    566\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[0;32m    567\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 568\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[0;32m    571\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n",
      "File \u001b[1;32mc:\\Users\\heeryung\\anaconda3\\envs\\jiwon2\\lib\\site-packages\\torch\\_tensor_str.py:328\u001b[0m, in \u001b[0;36m_tensor_str\u001b[1;34m(self, indent)\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[0;32m    326\u001b[0m     )\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 328\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[43m_Formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[1;32mc:\\Users\\heeryung\\anaconda3\\envs\\jiwon2\\lib\\site-packages\\torch\\_tensor_str.py:115\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mlen\u001b[39m(value_str))\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m     nonzero_finite_vals \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_select\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mne\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonzero_finite_vals\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;66;03m# no valid number, do nothing\u001b[39;00m\n\u001b[0;32m    121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for data in data_loader:\n",
    "    video = data['video'].cuda()\n",
    "    audio = data['audio'].cuda()\n",
    "    text = data['text'].cuda()\n",
    "    nframes = data['nframes'].cuda()\n",
    "    category = data['category'].cuda() # [batch_size,]\n",
    "\n",
    "    video = video.view(-1, video.shape[-1])\n",
    "    audio = audio.view(-1, audio.shape[-2], audio.shape[-1])\n",
    "    text = text.view(-1, text.shape[-2], text.shape[-1])\n",
    "\n",
    "    pred = net(video, audio, nframes, text, category) # [batch_size, 20]\n",
    "    print(pred)\n",
    "    pred_category = torch.argmax(pred, dim=1) # [batch_size,]\n",
    "    accuracy = torch.mean((pred_category == category).float()) # [batch_size,]\n",
    "    print(pred_category, '/', category)\n",
    "\n",
    "    total_accuracy += accuracy\n",
    "\n",
    "# Calculate final accuracies\n",
    "accuracy = total_accuracy / len(data_loader)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
       "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
       "          0.2847, -0.4040, -0.0351, -1.1323],\n",
       "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
       "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
       "          0.2847, -0.4040, -0.0351, -1.1323],\n",
       "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
       "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
       "          0.2847, -0.4040, -0.0351, -1.1323],\n",
       "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
       "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
       "          0.2847, -0.4040, -0.0351, -1.1323],\n",
       "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
       "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
       "          0.2847, -0.4040, -0.0351, -1.1323],\n",
       "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
       "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
       "          0.2847, -0.4040, -0.0351, -1.1323],\n",
       "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
       "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
       "          0.2847, -0.4040, -0.0351, -1.1323],\n",
       "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
       "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
       "          0.2847, -0.4040, -0.0351, -1.1323],\n",
       "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
       "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
       "          0.2847, -0.4040, -0.0351, -1.1323],\n",
       "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
       "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
       "          0.2847, -0.4040, -0.0351, -1.1323],\n",
       "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
       "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
       "          0.2847, -0.4040, -0.0351, -1.1323],\n",
       "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
       "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
       "          0.2847, -0.4040, -0.0351, -1.1323],\n",
       "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
       "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
       "          0.2847, -0.4040, -0.0351, -1.1323],\n",
       "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
       "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
       "          0.2847, -0.4040, -0.0351, -1.1323],\n",
       "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
       "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
       "          0.2847, -0.4040, -0.0351, -1.1323],\n",
       "        [ 0.3530, -0.7100, -0.0696,  0.8187, -0.0030, -0.5496, -0.4708,  0.6619,\n",
       "         -0.5395,  0.5044,  0.1096, -0.6115, -0.3472,  0.2192,  0.0657, -1.1334,\n",
       "          0.2847, -0.4040, -0.0351, -1.1323]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, p = torch.max(pred.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8187, 0.8187, 0.8187, 0.8187, 0.8187, 0.8187, 0.8187, 0.8187, 0.8187,\n",
       "        0.8187, 0.8187, 0.8187, 0.8187, 0.8187, 0.8187, 0.8187],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.randn(16,64,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.video_fc = nn.Linear(video_dim * embedding_size, 512)\n",
    "        self.audio_fc = nn.Linear(audio_dim * embedding_size, 512)\n",
    "        self.text_fc = nn.Linear(text_dim * embedding_size, 512)\n",
    "        self.final_fc = nn.Linear(512 * 3, num_classes)  # 3: 비디오, 오디오, 텍스트 입력의 수\n",
    "\n",
    "    def forward(self, video, audio, text):\n",
    "        video_flat = video.view(video.size(0), -1)\n",
    "        audio_flat = audio.view(audio.size(0), -1)\n",
    "        text_flat = text.view(text.size(0), -1)\n",
    "        \n",
    "        video_out = torch.relu(self.video_fc(video_flat))\n",
    "        audio_out = torch.relu(self.audio_fc(audio_flat))\n",
    "        text_out = torch.relu(self.text_fc(text_flat))\n",
    "        \n",
    "        combined = torch.cat((video_out, audio_out, text_out), dim=1)\n",
    "        logits = self.final_fc(combined)\n",
    "        return logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jiwon2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
